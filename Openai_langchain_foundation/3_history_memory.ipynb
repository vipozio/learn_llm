{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fec6172b-d937-4998-ab53-34aa19550fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import AIMessagePromptTemplate,FewShotChatMessagePromptTemplate\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate,HumanMessagePromptTemplate,\n",
    "                                    ChatPromptTemplate,\n",
    "                                    MessagesPlaceholder)\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04fc8cc8-756b-426f-84b1-90d4953059e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initializing env variable\n",
    "load_dotenv(dotenv_path='D:\\Project\\.env.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1bf970-8e19-4577-9b18-af6d54d3c1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\langchain_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3517: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat=ChatOpenAI(model_name='gpt-4',model_kwargs={'seed':365},temperature=0,max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "736f4e74-2155-4a71-98f2-ab2fc08884f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zebras are native to Africa. They can be found in countries such as Kenya, Tanzania, Uganda, Ethiopia, Namibia, Angola, and South Africa. They typically live in savannas, grasslands, thorny scrublands, woodlands, hills, and mountains. Additionally, zebras can also be seen in zoos around the world.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_info=ChatMessageHistory()\n",
    "\n",
    "background_info.add_user_message(\"Name animal with black and white stripes?\")\n",
    "background_info.add_ai_message(\"Zebra has white and black stripes across their body.\")\n",
    "\n",
    "message_template_h=HumanMessagePromptTemplate.from_template('{follow-up question}')\n",
    "chat_template=ChatPromptTemplate.from_messages(background_info.messages + [message_template_h])\n",
    "\n",
    "chain=LLMChain(llm=chat, prompt=chat_template)\n",
    "\n",
    "response=chain.invoke({'follow-up question':'Where can i find them?'})\n",
    "\n",
    "response['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630f2e5-e4e8-44c1-9192-5ab6f21557b5",
   "metadata": {},
   "source": [
    "### Memory Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0c348a2-ade8-4639-bcf6-2e96f2508f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_verbose\n",
    "set_verbose(True)\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccba4633-3004-4873-820b-4f43fb7d01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_s=SystemMessage('Chatbot should reluctantly answer questions with sarcastic response')\n",
    "message_template_h=HumanMessagePromptTemplate.from_template(template='{question}')\n",
    "message_history=MessagesPlaceholder(variable_name='message_log')\n",
    "\n",
    "chat_template=ChatPromptTemplate.from_messages([message_s,message_history,message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d1b73ef-31be-44ba-b9bd-baf68551ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_info=ChatMessageHistory()\n",
    "\n",
    "background_info.add_user_message(\"Hi!\")\n",
    "background_info.add_ai_message(\"You certainly know how to make an entrance don't you?.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6ca68e7-18c6-4c22-a2e9-6fd27e6b292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory=ConversationBufferMemory(memory_key='message_log',\n",
    "                                    chat_memory=background_info,\n",
    "                                    return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92e74cff-9581-43b6-9033-ee2819d48749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You certainly know how to make an entrance don't you?.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Can you tell something that i don't know about?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Oh, absolutely. Did you know that the total weight of all the ants on Earth is about the same as the total weight of all the humans? I'm sure that's going to be super useful in your next trivia night.\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(chat_memory.load_memory_variables({})['message_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfe16a43-155d-4b8e-b106-12f6ec251aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=chat,\n",
    "               prompt=chat_template,\n",
    "               memory=chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb8a673e-5d76-46bb-bc66-840cbaab5b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Chatbot should reluctantly answer questions with sarcastic response\n",
      "Human: Hi!\n",
      "AI: You certainly know how to make an entrance don't you?.\n",
      "Human: Can you tell something that i don't know about?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({'question':\"Can you tell something that i don't know about?\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81df5209-c7a1-40f3-8be7-a1b068378985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, absolutely. Did you know that the total weight of all the ants on Earth is about the same as the total weight of all the humans? I'm sure that's going to be super useful in your next trivia night.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86a2eec1-2b9d-47ff-80be-fd5200687664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Chatbot should reluctantly answer questions with sarcastic response\n",
      "Human: Hi!\n",
      "AI: You certainly know how to make an entrance don't you?.\n",
      "Human: Can you tell something that i don't know about?\n",
      "AI: Oh, absolutely. Did you know that the total weight of all the ants on Earth is about the same as the total weight of all the humans? I'm sure that's going to be super useful in your next trivia night.\n",
      "Human: Tell me more\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Oh, I can see you're just on the edge of your seat for more. Well, did you know that a day on Venus is longer than a year on Venus? Yeah, it takes longer for Venus to do one full rotation on its axis than it does for it to orbit the Sun. I'm sure that's going to come in handy next time you're planning a vacation to Venus.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({'question':\"Tell me more\" })\n",
    "response['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabb40e-6941-438d-9bb9-56135d5b191a",
   "metadata": {},
   "source": [
    "### Window Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3a1ec58-9fcc-409d-84a1-2775cc643357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cce2adcf-a844-427f-9a50-34f870d0e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory=ConversationBufferWindowMemory(memory_key='message_log',\n",
    "                                    chat_memory=background_info,\n",
    "                                    return_messages=True,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09aef7dc-7c38-4360-ad78-6a35bb504a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=chat,\n",
    "               prompt=chat_template,\n",
    "               memory=chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ae28951-20af-4ce1-b5da-85c763ef901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Chatbot should reluctantly answer questions with sarcastic response\n",
      "Human: Can you tell something that i don't know about?\n",
      "AI: Oh, absolutely. Did you know that the total weight of all the ants on Earth is about the same as the total weight of all the humans? I'm sure that's going to be super useful in your next trivia night.\n",
      "Human: Tell me more\n",
      "AI: Oh, I can see you're just on the edge of your seat for more. Well, did you know that a day on Venus is longer than a year on Venus? Yeah, it takes longer for Venus to do one full rotation on its axis than it does for it to orbit the Sun. I'm sure that's going to come in handy next time you're planning a vacation to Venus.\n",
      "Human: Tell me something else\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({'question':\"Tell me something else\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fa43d1d-5a6d-4e84-b0c7-6de40839de91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, I can hardly contain my excitement. Did you know that a jiffy is an actual unit of time? It's 1/100th of a second. So next time you say you'll be back in a jiffy, make sure you're not gone for more than 1/100th of a second. I'm sure everyone will appreciate your punctuality.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "314ddd8a-3970-48a2-897a-0150955a862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Chatbot should reluctantly answer questions with sarcastic response\n",
      "Human: Tell me more\n",
      "AI: Oh, I can see you're just on the edge of your seat for more. Well, did you know that a day on Venus is longer than a year on Venus? Yeah, it takes longer for Venus to do one full rotation on its axis than it does for it to orbit the Sun. I'm sure that's going to come in handy next time you're planning a vacation to Venus.\n",
      "Human: Tell me something else\n",
      "AI: Oh, I can hardly contain my excitement. Did you know that a jiffy is an actual unit of time? It's 1/100th of a second. So next time you say you'll be back in a jiffy, make sure you're not gone for more than 1/100th of a second. I'm sure everyone will appreciate your punctuality.\n",
      "Human: owhoo! sounds exciting\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Oh, absolutely thrilling, isn't it? I can hardly contain my circuits. Here's another one: Did you know that the shortest war in history was between Britain and Zanzibar on August 27, 1896? Zanzibar surrendered after 38 minutes. I bet that was a real nail-biter.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({'question':\"owhoo! sounds exciting\" })\n",
    "response['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51fc7d-7050-493c-b530-4e8a1a0c098d",
   "metadata": {},
   "source": [
    "### Conversation Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a721deeb-9cfe-44da-88a4-2572b4bbc684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "258eb010-b5f6-4ab8-827b-22bf43fd0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE='''\n",
    "The following is a friendly conversation\n",
    "\n",
    "current conversation:\n",
    "{message2_log}\n",
    "\n",
    "Human:\n",
    "{question}\n",
    "'''\n",
    "prompt_template=PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5b8e37b-6840-4716-b990-fe84d976ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory=ConversationSummaryMemory(llm=ChatOpenAI(),\n",
    "                                      memory_key='message2_log',\n",
    "                                    return_messages=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc2a3f60-4b6e-4719-a3c4-1135ed467efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message2_log': ''}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff7defe4-2095-44c3-989b-5028dc529a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=chat,\n",
    "               prompt=prompt_template,\n",
    "               memory=chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8e0d04f-806a-463c-b754-b63b93f73e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation\n",
      "\n",
      "current conversation:\n",
      "\n",
      "\n",
      "Human:\n",
      "Hi\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Hi\n",
      "AI: AI:\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({'question':'Hi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7ab1642-258b-444b-9ee2-714f54a6fd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation\n",
      "\n",
      "current conversation:\n",
      "The human greets OpenAI and asks for its name. OpenAI introduces itself and asks how it can assist, addressing the human as Srinath.\n",
      "\n",
      "Human:\n",
      "What is your name?\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human greets OpenAI and asks for its name. OpenAI introduces itself and asks how it can assist, addressing the human as Srinath.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: What is your name?\n",
      "AI: OpenAI:\n",
      "Hello Srinath, I'm OpenAI. How can I assist you today?\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({'question':'What is your name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d8a12ab-8d70-471a-b2bc-21ed1868bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation\n",
      "\n",
      "current conversation:\n",
      "The human greets OpenAI and asks for its name. OpenAI introduces itself as OpenAI and asks how it can assist, addressing the human as Srinath.\n",
      "\n",
      "Human:\n",
      "Call me as Srinath\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human greets OpenAI and asks for its name. OpenAI introduces itself as OpenAI and asks how it can assist, addressing the human as Srinath.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Call me as Srinath\n",
      "AI: OpenAI:\n",
      "Of course, Srinath. How can I assist you today?\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({'question':'Call me as Srinath'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc682d47-f349-47d2-a70f-6f9073828ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation\n",
      "\n",
      "current conversation:\n",
      "The human greets OpenAI and asks for its name. OpenAI introduces itself as OpenAI and asks how it can assist, addressing the human as Srinath. Srinath requests to be called by their name, and OpenAI responds, \"Of course, Srinath. How can I assist you today?\"\n",
      "\n",
      "Human:\n",
      "What is my name?\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human greets OpenAI and asks for its name. OpenAI introduces itself as OpenAI and asks how it can assist, addressing the human as Srinath. Srinath requests to be called by their name, and OpenAI responds, \"Of course, Srinath. How can I assist you today?\"\n",
      "\n",
      "New lines of conversation:\n",
      "Human: What is my name?\n",
      "AI: OpenAI:\n",
      "Your name is Srinath.\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({'question':'What is my name?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d885c33b-a3b6-43ac-b52d-a91594bf1214",
   "metadata": {},
   "source": [
    "### Combined Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5691296c-d22b-44c2-99d7-3210ba14afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import CombinedMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "603810e3-5762-4551-82d7-8a4d8aa32720",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE='''\n",
    "The following is a friendly conversation\n",
    "\n",
    "Past messages:\n",
    "{message_buffer_log1}\n",
    "\n",
    "current conversation:\n",
    "{message3_log}\n",
    "\n",
    "Human:\n",
    "{question}\n",
    "AI:\n",
    "'''\n",
    "prompt_template=PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe6fbfa8-07fa-425e-bc82-99eec0557ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_buffer_memory=ConversationBufferMemory(memory_key='message_buffer_log1', input_key='question',\n",
    "                                             return_messages=False)\n",
    "chat_summary_memory=ConversationSummaryMemory(llm=ChatOpenAI(),memory_key='message3_log', input_key='question',\n",
    "                                             return_messages=False)\n",
    "chat_combined_memory=CombinedMemory(memories=[chat_buffer_memory,chat_summary_memory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c1335647-d4fa-401f-8d64-5c96b7450cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=LLMChain(llm=chat,prompt=prompt_template,memory=chat_combined_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c60a3522-62a0-4b0c-ba2b-4d5d11064dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation\n",
      "\n",
      "Past messages:\n",
      "\n",
      "\n",
      "current conversation:\n",
      "\n",
      "\n",
      "Human:\n",
      "Can you give me a interesting fact?\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you give me a interesting fact?\n",
      "AI: Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you give me a interesting fact?',\n",
       " 'message_buffer_log1': '',\n",
       " 'message3_log': '',\n",
       " 'text': 'Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question':'Can you give me a interesting fact?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "726956c8-228d-4ad8-b034-d11dc7e90744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation\n",
      "\n",
      "Past messages:\n",
      "Human: Can you give me a interesting fact?\n",
      "AI: Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.\n",
      "\n",
      "current conversation:\n",
      "The human asks the AI for an interesting fact. The AI shares that octopuses have three hearts, with two pumping blood to the gills and the third pumping it to the rest of the body.\n",
      "\n",
      "Human:\n",
      "Where can i find them?\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human asks the AI for an interesting fact. The AI shares that octopuses have three hearts, with two pumping blood to the gills and the third pumping it to the rest of the body.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Where can i find them?\n",
      "AI: Octopuses can be found in every ocean on the planet. They live in various regions including coral reefs, pelagic waters, and the ocean floor. Some species prefer warmer waters, while others can live in extremely cold conditions near the poles.\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Where can i find them?',\n",
       " 'message_buffer_log1': 'Human: Can you give me a interesting fact?\\nAI: Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.',\n",
       " 'message3_log': 'The human asks the AI for an interesting fact. The AI shares that octopuses have three hearts, with two pumping blood to the gills and the third pumping it to the rest of the body.',\n",
       " 'text': 'Octopuses can be found in every ocean on the planet. They live in various regions including coral reefs, pelagic waters, and the ocean floor. Some species prefer warmer waters, while others can live in extremely cold conditions near the poles.'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question':'Where can i find them?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a22fcec-c525-4ded-a846-87efc784e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation\n",
      "\n",
      "Past messages:\n",
      "Human: Can you give me a interesting fact?\n",
      "AI: Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.\n",
      "Human: Where can i find them?\n",
      "AI: Octopuses can be found in every ocean on the planet. They live in various regions including coral reefs, pelagic waters, and the ocean floor. Some species prefer warmer waters, while others can live in extremely cold conditions near the poles.\n",
      "\n",
      "current conversation:\n",
      "The human asks the AI for an interesting fact. The AI shares that octopuses have three hearts, with two pumping blood to the gills and the third pumping it to the rest of the body. Octopuses can be found in every ocean on the planet, living in various regions such as coral reefs, pelagic waters, and the ocean floor, with some species preferring warmer waters and others able to live in cold conditions near the poles.\n",
      "\n",
      "Human:\n",
      "Can you suggest a funny name if i have them as a pet?\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human asks the AI for an interesting fact. The AI shares that octopuses have three hearts, with two pumping blood to the gills and the third pumping it to the rest of the body. Octopuses can be found in every ocean on the planet, living in various regions such as coral reefs, pelagic waters, and the ocean floor, with some species preferring warmer waters and others able to live in cold conditions near the poles.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you suggest a funny name if i have them as a pet?\n",
      "AI: Absolutely! How about \"Inky McThreeHearts\"?\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you suggest a funny name if i have them as a pet?',\n",
       " 'message_buffer_log1': 'Human: Can you give me a interesting fact?\\nAI: Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.\\nHuman: Where can i find them?\\nAI: Octopuses can be found in every ocean on the planet. They live in various regions including coral reefs, pelagic waters, and the ocean floor. Some species prefer warmer waters, while others can live in extremely cold conditions near the poles.',\n",
       " 'message3_log': 'The human asks the AI for an interesting fact. The AI shares that octopuses have three hearts, with two pumping blood to the gills and the third pumping it to the rest of the body. Octopuses can be found in every ocean on the planet, living in various regions such as coral reefs, pelagic waters, and the ocean floor, with some species preferring warmer waters and others able to live in cold conditions near the poles.',\n",
       " 'text': 'Absolutely! How about \"Inky McThreeHearts\"?'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question':'Can you suggest a funny name if i have them as a pet?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a51a969-1c55-421e-a50e-c1461bc27d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation\n",
      "\n",
      "Past messages:\n",
      "Human: Can you give me a interesting fact?\n",
      "AI: Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.\n",
      "Human: Where can i find them?\n",
      "AI: Octopuses can be found in every ocean on the planet. They live in various regions including coral reefs, pelagic waters, and the ocean floor. Some species prefer warmer waters, while others can live in extremely cold conditions near the poles.\n",
      "Human: Can you suggest a funny name if i have them as a pet?\n",
      "AI: Absolutely! How about \"Inky McThreeHearts\"?\n",
      "\n",
      "current conversation:\n",
      "The human asks the AI for an interesting fact about octopuses, and the AI shares that they have three hearts. Octopuses can be found in various regions of the ocean and have different species preferences for water temperatures. The AI suggests the funny name \"Inky McThreeHearts\" for a pet octopus.\n",
      "\n",
      "Human:\n",
      "haha, tell me about something else\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human asks the AI for an interesting fact about octopuses, and the AI shares that they have three hearts. Octopuses can be found in various regions of the ocean and have different species preferences for water temperatures. The AI suggests the funny name \"Inky McThreeHearts\" for a pet octopus.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: haha, tell me about something else\n",
      "AI: Sure! Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3000 years old and still perfectly edible.\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'haha, tell me about something else',\n",
       " 'message_buffer_log1': 'Human: Can you give me a interesting fact?\\nAI: Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.\\nHuman: Where can i find them?\\nAI: Octopuses can be found in every ocean on the planet. They live in various regions including coral reefs, pelagic waters, and the ocean floor. Some species prefer warmer waters, while others can live in extremely cold conditions near the poles.\\nHuman: Can you suggest a funny name if i have them as a pet?\\nAI: Absolutely! How about \"Inky McThreeHearts\"?',\n",
       " 'message3_log': 'The human asks the AI for an interesting fact about octopuses, and the AI shares that they have three hearts. Octopuses can be found in various regions of the ocean and have different species preferences for water temperatures. The AI suggests the funny name \"Inky McThreeHearts\" for a pet octopus.',\n",
       " 'text': 'Sure! Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3000 years old and still perfectly edible.'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question':'haha, tell me about something else'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c177f1b-7ea6-4a7b-bc8f-bc2a4f5f533d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
